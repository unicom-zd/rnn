{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "status = ['AT', 'LT']\n",
    "# 16.02 \n",
    "# load data of Feb, 16\n",
    "month = ['10', '11', '12']\n",
    "day = {'10':31, '11':30, '12':31}\n",
    "data_prefix = 'ori-data/sorted-data-02/sorted-ZDJM_3GD_02_2015'\n",
    "# the order of properties MATTERS!!!\n",
    "properties = ['BILL', 'CALL', 'CREDIT', 'DEPOSIT',\n",
    "              'PAYDEPOSIT', 'INCOME', 'STREAM', 'STATE']\n",
    "# end of 16.02\n",
    "\n",
    "# # 16.03\n",
    "# # load data of March, 16\n",
    "# month = ['1511', '1512', '1601']\n",
    "# day = {'1511':30, '1512':31, '1601':31}\n",
    "# data_prefix = 'ori-data/sorted-data-03/sorted-ZDJM_3GD_03_20'\n",
    "# # the order of properties MATTERS!!!\n",
    "# properties = ['BILL', 'CALL', 'CREDIT', 'DEPOSIT',\n",
    "#               'PDEPOSIT', 'INCOME', 'STREAM', 'STATE']\n",
    "# # end of 16.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "used_st = ['0','1','2','4','5','6',\n",
    "           '7','9','A','B','F','K',\n",
    "           'L','O','T','U','']\n",
    "st_to_id = {used_st[i]:i for i in xrange(len(used_st))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# if month = ['1511', '1512', '1601'] and day = {'1511':30, '1512':31, '1601':31}\n",
    "# then used_day = {1:31, 2:62, 3:92}\n",
    "# keys are the number of used month, and values are the corresponding sum of day\n",
    "used_day = {}\n",
    "for used_month in xrange(len(day.keys())+1):\n",
    "    used_day[used_month] = sum([day[m] for m in month[-used_month:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 16.02\n",
    "# load data of Feb, 16\n",
    "NUM_OF_AT_USER = 2110176\n",
    "NUM_OF_LT_USER = 93827\n",
    "# end of 16.02\n",
    "\n",
    "# # 16.03\n",
    "# # load data of March, 16\n",
    "# NUM_OF_AT_USER = 2048501\n",
    "# NUM_OF_LT_USER = 88842\n",
    "# # end of 16.03\n",
    "\n",
    "NUM_OF_STATE = 17\n",
    "TRAIN_FRAC = 0.6\n",
    "VALI_FRAC = 0.2\n",
    "assert(NUM_OF_STATE == len(used_st))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def csv_to_np(filename, deli, data):\n",
    "    '''\n",
    "    load csv to data\n",
    "    remove first column of csv\n",
    "    ''' \n",
    "    print filename, data.shape\n",
    "    num_of_user, num_of_day = data.shape\n",
    "    with open(filename, 'r') as f:\n",
    "        for user, line in enumerate(f.readlines()):\n",
    "            sp_line = line.split(deli)\n",
    "            assert(len(sp_line) == num_of_day + 1)\n",
    "            for day, num in enumerate(sp_line[1:]):\n",
    "                data[user, day] = float(num)\n",
    "        assert(user + 1 == num_of_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def state_to_np(filename, deli, data):\n",
    "    '''\n",
    "    load state.csv to data\n",
    "    if a state is presented, set to 1\n",
    "    otherwise, set to -1\n",
    "    remove first column of csv\n",
    "    '''\n",
    "    print filename, data.shape\n",
    "    num_of_user, num_of_day, num_of_state = data.shape\n",
    "    data.fill(-1.0)\n",
    "    with open(filename, 'r') as f:\n",
    "        for user, line in enumerate(f.readlines()):\n",
    "            sp_line = line.split(deli)\n",
    "            assert(len(sp_line) == num_of_day + 1)\n",
    "            for day, st in enumerate(sp_line[1:]):\n",
    "                st = st.replace('\\n', '')\n",
    "                data[user, day, st_to_id[st]] = 1.0\n",
    "        assert(user + 1 == num_of_user)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data(used_month, used_status, total_number_of_prpty):\n",
    "    '''\n",
    "    load all csv matching used_status and used_month\n",
    "    example:\n",
    "        supposed wanting to load data of march, then\n",
    "        use previous comment section labeling 16.03\n",
    "        \n",
    "        if used_month = 2 and used_status = 'AT', then\n",
    "        this function will load ZDJM_3GD_03_201512_AT_*.csv\n",
    "        and ZDJM_3GD_03_201601_AT_*.csv\n",
    "    '''\n",
    "    def get_state_day_range(used_month):\n",
    "        '''\n",
    "        calculate the index range in data of all used month\n",
    "        if used_month = 2 and loading data of 16.03,\n",
    "        then day_range = {'1512':(0,31), '1601':(31,62)}\n",
    "        '''\n",
    "        day_range = {}\n",
    "        for mo_idx, mo in enumerate(month[-used_month:]):\n",
    "            if mo_idx == 0:\n",
    "                day_range[mo] = (0, day[mo])\n",
    "            else:\n",
    "                prev_mo = month[-used_month+mo_idx-1]\n",
    "                _, prev_end = day_range[prev_mo]\n",
    "                day_range[mo] = (prev_end, prev_end+day[mo])\n",
    "        \n",
    "        return day_range\n",
    "    \n",
    "    day_range = get_state_day_range(used_month)\n",
    "    num_of_row = NUM_OF_LT_USER if used_status == 'LT' else NUM_OF_AT_USER\n",
    "    # initial data\n",
    "    data = np.zeros((num_of_row, used_day[used_month], total_number_of_prpty))\n",
    "    print data.shape\n",
    "    \n",
    "    for pr_idx, pr in enumerate(properties):\n",
    "        print 'loading', pr\n",
    "        if pr != 'STATE':\n",
    "            for mo in month[-used_month:]:\n",
    "                st_day, end_day = day_range[mo]\n",
    "                print 'loading', mo, used_status, pr\n",
    "                print 'start from', st_day, 'to', end_day\n",
    "                # load csv to data[:, st_day:end_day, pr_idx]\n",
    "                csv_to_np(data_prefix+'%s_%s_%s.csv' % (mo,used_status,pr),\n",
    "                          ',', data[:, st_day:end_day, pr_idx])\n",
    "            \n",
    "            # whiten\n",
    "            d_aver = data[:, :, pr_idx].mean(axis=1)\n",
    "            d_aver = d_aver.reshape(len(d_aver),1)\n",
    "            d_std = data[:, :, pr_idx].std(axis=1)\n",
    "            d_std = d_std.reshape(len(d_std),1)\n",
    "            data[:, :, pr_idx] -= d_aver\n",
    "            data[:, :, pr_idx] /= (d_std + 1e-5)\n",
    "                \n",
    "        else: # pr == 'STATE'\n",
    "            for mo in month[-used_month:]:\n",
    "                st_day, end_day = day_range[mo]\n",
    "                print 'loading', mo, used_status, pr\n",
    "                # load csv to data[:, st_day:end_day, pr_idx:]\n",
    "                state_to_np(data_prefix+'%s_%s_%s.csv' % (mo,used_status,pr),\n",
    "                            ',', data[:, st_day:end_day, pr_idx:])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_hdf5(name):\n",
    "    '''\n",
    "    load data from hdf5 file with filename\n",
    "    '''\n",
    "    import h5py\n",
    "    with h5py.File(name+'.h5', 'r') as hf:\n",
    "        return np.copy(hf[name])\n",
    "\n",
    "def dump_hdf5(name, data):\n",
    "    '''\n",
    "    dump data to hdf5 file with name as filename and index\n",
    "    '''\n",
    "    import h5py\n",
    "    with h5py.File(name+'.h5', 'w') as hf:\n",
    "        hf.create_dataset(name, data=data, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def csv_to_h5():\n",
    "    for p in product([1,2,3], ['LT','AT'], [24]):\n",
    "        print 'dumping', p\n",
    "        d = apply(load_data, p)\n",
    "        dump_hdf5('%sm_%s_24pr' % (str(p[0]),p[1]), d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for p in product([2], ['AT'], [24]):\n",
    "    print 'dumping', p\n",
    "    d = apply(load_data, p)\n",
    "    dump_hdf5('1602_%sm_%s_24pr' % (str(p[0]),p[1]), d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def shuf_split_data(data, tr_frac, val_frac):\n",
    "    '''split data into train, validate and test set'''\n",
    "    assert(0 < tr_frac < 1)\n",
    "    assert(0 < val_frac < 1)\n",
    "    assert(0 < 1 - tr_frac - val_frac < 1)\n",
    "    np.random.shuffle(data)\n",
    "    split_tr_id = int(len(data) * tr_frac)\n",
    "    split_val_id = int(len(data) * val_frac)\n",
    "    split_te_id = split_tr_id + split_val_id\n",
    "    return (data[:split_tr_id], # train\n",
    "            data[split_tr_id:split_te_id], # val\n",
    "            data[split_te_id:]) # test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_h5_and_split(name):\n",
    "    '''\n",
    "    load data produced by load_data function (as hdf5 file)\n",
    "    and split into train, validate and test set\n",
    "    '''\n",
    "    data = load_hdf5(name)\n",
    "    print 'data', data.shape\n",
    "    tr_data, val_data, te_data = shuf_split_data(data, TRAIN_FRAC, VALI_FRAC)\n",
    "    print 'train', name, tr_data.shape\n",
    "    dump_hdf5('tr_'+name, tr_data)\n",
    "    print 'validate', name, val_data.shape\n",
    "    dump_hdf5('val_'+name, val_data)\n",
    "    print 'test', name, te_data.shape\n",
    "    dump_hdf5('te_'+name, te_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load_h5_and_split('1m_LT_23pr')\n",
    "# load_h5_and_split('1m_AT_23pr')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
